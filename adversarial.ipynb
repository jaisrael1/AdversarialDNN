{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m17\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(17)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download dataset and prepare dataloaders\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "test_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "full_train_dataset = datasets.CIFAR10(root='data', train=True, transform=train_transforms, download=True)\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(full_train_dataset, [40000, 10000])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='data', train=False, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=2, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=BATCH_SIZE, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, num_workers=2, shuffle=False)\n",
    "\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "def train(model, weight_decay=0):\n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "\n",
    "    # Store losses to plot after training finishes\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        # Track training + validation loss\n",
    "        train_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass - compute predictions by passing input through model\n",
    "            output = model(data)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            # Backpropogation: compute gradient of loss w/ respect to model parameters\n",
    "            loss.backward()\n",
    "            # Backpropogation: Update parameters using loss gradient\n",
    "            optimizer.step()\n",
    "            # Update train loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # Check accuracy on validation set to make sure we don't overfit\n",
    "        model.eval()\n",
    "        for data, target in validation_loader:\n",
    "            # Forward pass - compute predictions by passing input through model\n",
    "            output = model(data)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            # Update validation loss\n",
    "            validation_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        # Calculate average train and validation losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        validation_loss = validation_loss/len(validation_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        validation_losses.append(validation_loss)\n",
    "            \n",
    "        # Display training and validation loss and accuracy every epoch \n",
    "        train_accuracy = get_accuracy(model, train_loader, DEVICE)\n",
    "        validation_accuracy = get_accuracy(model, validation_loader, DEVICE)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTraining Accuracy: {:.6f} \\tValidation Accuracy: {:.6f}'.format(\n",
    "            epoch, train_loss, validation_loss, train_accuracy, validation_accuracy))\n",
    "    return train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get accuracy of model\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            predictions = model(features)\n",
    "            _, predicted_labels = torch.max(predictions, 1)\n",
    "\n",
    "            # Increment correct count by number of correct predictions in batch\n",
    "            num_correct += (predicted_labels == targets).sum()\n",
    "        return num_correct.float()/len(data_loader.dataset) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and save weights to a file\n",
    "\n",
    "model_vanilla = LeNetVanilla()\n",
    "train_losses, validation_losses = train(model_vanilla)\n",
    "\n",
    "MODEL_PATH = \"models/\"\n",
    "torch.save({'state_dict': model_vanilla.state_dict()}, MODEL_PATH + \"LeNet_vanilla.pth\")\n",
    "\n",
    "plt.plot([*range(NUM_EPOCHS)], train_losses, color='blue', label='Train Loss')\n",
    "plt.plot([*range(NUM_EPOCHS)], validation_losses, color='green', label='Validation Loss')\n",
    "leg = plt.legend(loc='upper center')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Performance of Vanilla LeNet model during training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify image using FGSM attack \n",
    "def fgsm_perturb(image, epsilon, gradient):\n",
    "    # Modify image by adjusting all of the pixels\n",
    "    perturbed_image = image + epsilon*gradient.sign()\n",
    "    # Clip to 0,1 raange\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1c187762543b7b51aa9f108e7f8545cb0c5a4f42c9141b7d72049c956d6c53f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
