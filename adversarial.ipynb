{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m17\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(17)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download dataset and prepare dataloaders\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "test_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "full_train_dataset = datasets.CIFAR10(root='data', train=True, transform=train_transforms, download=True)\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(full_train_dataset, [40000, 10000])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='data', train=False, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=2, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=BATCH_SIZE, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, num_workers=2, shuffle=False)\n",
    "\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "def train(model, weight_decay=0):\n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "\n",
    "    # Store losses to plot after training finishes\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        # Track training + validation loss\n",
    "        train_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass - compute predictions by passing input through model\n",
    "            output = model(data)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            # Backpropogation: compute gradient of loss w/ respect to model parameters\n",
    "            loss.backward()\n",
    "            # Backpropogation: Update parameters using loss gradient\n",
    "            optimizer.step()\n",
    "            # Update train loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # Check accuracy on validation set to make sure we don't overfit\n",
    "        model.eval()\n",
    "        for data, target in validation_loader:\n",
    "            # Forward pass - compute predictions by passing input through model\n",
    "            output = model(data)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            # Update validation loss\n",
    "            validation_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        # Calculate average train and validation losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        validation_loss = validation_loss/len(validation_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        validation_losses.append(validation_loss)\n",
    "            \n",
    "        # Display training and validation loss and accuracy every epoch \n",
    "        train_accuracy = get_accuracy(model, train_loader, DEVICE)\n",
    "        validation_accuracy = get_accuracy(model, validation_loader, DEVICE)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTraining Accuracy: {:.6f} \\tValidation Accuracy: {:.6f}'.format(\n",
    "            epoch, train_loss, validation_loss, train_accuracy, validation_accuracy))\n",
    "    return train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get accuracy of model\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            predictions = model(features)\n",
    "            _, predicted_labels = torch.max(predictions, 1)\n",
    "\n",
    "            # Increment correct count by number of correct predictions in batch\n",
    "            num_correct += (predicted_labels == targets).sum()\n",
    "        return num_correct.float()/len(data_loader.dataset) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and save weights to a file\n",
    "\n",
    "model_vanilla = LeNetVanilla()\n",
    "train_losses, validation_losses = train(model_vanilla)\n",
    "\n",
    "MODEL_PATH = \"models/\"\n",
    "torch.save({'state_dict': model_vanilla.state_dict()}, MODEL_PATH + \"LeNet_vanilla.pth\")\n",
    "\n",
    "plt.plot([*range(NUM_EPOCHS)], train_losses, color='blue', label='Train Loss')\n",
    "plt.plot([*range(NUM_EPOCHS)], validation_losses, color='green', label='Validation Loss')\n",
    "leg = plt.legend(loc='upper center')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Performance of Vanilla LeNet model during training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify image using FGSM attack \n",
    "def fgsm_perturb(image, epsilon, gradient):\n",
    "    # Modify image by adjusting all of the pixels\n",
    "    perturbed_image = image + epsilon*gradient.sign()\n",
    "    # Clip to 0,1 raange\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def igsm_perturb(model, image, target, epsilon, alpha, iters): \n",
    "    # Forward pass, get least likely class\n",
    "    output = model(image)\n",
    "    ll_label = torch.min(output, 1)[1] # get index of the min log-prob  \n",
    "    \n",
    "    if iters == 0 :\n",
    "        # Chose epochs based on epsilon value\n",
    "        iters = int(min(epsilon + 4, 1.25*epsilon))\n",
    "    \n",
    "    # Data is in range [0,1] scale epsilon down by 255.\n",
    "    epsilon = epsilon/255\n",
    "    \n",
    "    for i in range(iters) : \n",
    "        # Prepare to use input gradient\n",
    "        image.requires_grad = True\n",
    "        \n",
    "        # Forward pass \n",
    "        output = model(image)\n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # Don't attack if prediction is already wrong\n",
    "        if init_pred.item() != target.item():\n",
    "            return image\n",
    "\n",
    "        loss = F.nll_loss(output, ll_label) \n",
    "        model.zero_grad()\n",
    "\n",
    "        # Backward pass to calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = image.grad.data\n",
    "\n",
    "        # Collect the element-wise sign of the data gradient\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        # Create the perturbed image by adjusting each pixel of the input image\n",
    "        perturbed_image = image - alpha*sign_data_grad\n",
    "        \n",
    "                \n",
    "        # Clip image for next iteration\n",
    "        first = torch.clamp(image - epsilon, min=0)  \n",
    "        second = (perturbed_image>=first).float() * perturbed_image + (first>perturbed_image).float() * first\n",
    "        third = (second > image+epsilon).float() * (image+epsilon) + (image+epsilon >= second).float() * second\n",
    "        image = torch.clamp(third, max=1).detach_()\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_test(model, device, test_loader, epsilon, alpha=0.006, iters=20, attack=\"fgsm\"):\n",
    "    # Keep track of correctly classified examples\n",
    "    correct = 0\n",
    "    sample_images = []\n",
    "\n",
    "    # Go through all test images\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Preparing to modify gradient w/ respect to image\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        # Get highest probability as prediction\n",
    "        initial_pred = output.max(1, keepdim=True)[1] \n",
    "\n",
    "        # If the initial prediction was wrong, we dont have to attack this sample\n",
    "        if initial_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients w/ respect to loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Get data gradient\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        if attack==\"fgsm\":\n",
    "            # Call FGSM Attack\n",
    "            perturbed_data = fgsm_perturb(data, epsilon, data_grad)\n",
    "        else:\n",
    "            # Call IGSM attack\n",
    "            perturbed_data = igsm_perturb(model, data, target, epsilon, alpha, iters)\n",
    "\n",
    "        # Run perturbed image through model, get prediction\n",
    "        output = model(perturbed_data)\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "        else:\n",
    "            # Save samples to display after predictions\n",
    "            if len(sample_images) < 5:\n",
    "                img_ptg = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                sample_images.append((initial_pred.item(), final_pred.item(), img_ptg))\n",
    "\n",
    "    # Calculate final accuracy for this value of epsilon\n",
    "    accuracy = correct/float(len(test_loader))\n",
    "    print(f\"Epsilon: {epsilon}\\tTest Accuracy = {accuracy}\")\n",
    "\n",
    "    # Return accuracy and some images to display\n",
    "    return accuracy, sample_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    print('Test accuracy (benign images): %.2f%%' % (get_accuracy(model_vanilla, test_loader, DEVICE)))a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons_fgsm = [.05, .12, .3]\n",
    "epsilons_igsm = [2, 4, 8, 16]\n",
    "\n",
    "accuracies_fgsm = []\n",
    "accuracies_igsm = []\n",
    "examples_fgsm = []\n",
    "examples_igsm = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "print(\"fgsm testing\")\n",
    "for eps in epsilons_fgsm:\n",
    "    acc, ex = attack_test(model_vanilla, DEVICE, test_loader, eps, attack=\"fgsm\")\n",
    "    accuracies_fgsm.append(acc)\n",
    "    examples_fgsm.append(ex)\n",
    "\n",
    "print(\"igsm testing\")\n",
    "for eps in epsilons_igsm:\n",
    "    acc, ex = attack_test(model_vanilla, DEVICE, test_loader, eps, 0.006, 20, attack=\"igsm\")\n",
    "    accuracies_igsm.append(acc)\n",
    "    examples_igsm.append(ex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some FGSM modified images at different epsilons\n",
    "def showImages(examples, epsilons, title):\n",
    "    count = 0\n",
    "    plt.figure(figsize=(8,10))\n",
    "    for i in range(len(epsilons_fgsm)):\n",
    "        for j in range(len(examples[i])):\n",
    "            count += 1\n",
    "            plt.subplot(len(epsilons),len(examples[0]),count)\n",
    "            plt.xticks([], [])\n",
    "            plt.yticks([], [])\n",
    "            # Add epsilon label to the beginning of each row\n",
    "            if j == 0:\n",
    "                plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "            original,adv,example = examples[i][j]\n",
    "            plt.title(\"{} -> {}\".format(labels[original], labels[adv]))\n",
    "            example = example.swapaxes(0,1)\n",
    "            example = example.swapaxes(1,2)\n",
    "            plt.imshow(example, cmap=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImages(examples_fgsm, epsilons_fgsm, \"FGSM attacked images on no-defense model\")\n",
    "showImages(examples_igsm, epsilons_igsm, \"IGSM attacked images on no-defense model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune model using adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with 75% perturbed images\n",
    "def train_adversarial(model, weight_decay=0):\n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "\n",
    "    # Store losses to plot after training finishes\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        # Track training + validation loss\n",
    "        train_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "        correct = 0\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            # Perturb image 75% of the time\n",
    "            if random.random() < 0.75:\n",
    "                # Preparing to modify gradient w/ respect to image\n",
    "                data.requires_grad = True\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(data)\n",
    "                # Get highest probability as prediction\n",
    "                initial_pred = output.max(1, keepdim=True)[1] \n",
    "                loss = F.nll_loss(output, target)\n",
    "                model.zero_grad()\n",
    "\n",
    "                # Calculate gradients w/ respect to loss\n",
    "                loss.backward()\n",
    "\n",
    "                # Get data gradient\n",
    "                data_grad = data.grad.data\n",
    "\n",
    "                # Call FGSM Attack\n",
    "                data = fgsm_perturb(data, 0.12, data_grad)\n",
    "            \n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            # Backwards pass\n",
    "            loss.backward()\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            # Update train loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # Check accuracy on validation set to prevent overfitting\n",
    "        model.eval()\n",
    "        for data, target in validation_loader:\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            # Update validation loss\n",
    "            validation_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        # Calculate average train and validation losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        validation_loss = validation_loss/len(validation_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        validation_losses.append(validation_loss)\n",
    "            \n",
    "        # Display training and validation loss and accuracy every epoch \n",
    "        train_accuracy = get_accuracy(model, train_loader, DEVICE)\n",
    "        validation_accuracy = get_accuracy(model, validation_loader, DEVICE)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTraining Accuracy: {:.6f} \\tValidation Accuracy: {:.6f}'.format(\n",
    "            epoch, train_loss, validation_loss, train_accuracy, validation_accuracy))\n",
    "    return train_losses, validation_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1c187762543b7b51aa9f108e7f8545cb0c5a4f42c9141b7d72049c956d6c53f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
